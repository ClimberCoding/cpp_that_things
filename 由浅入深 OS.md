# 由浅入深 OS

## 0.0、前言

我们学习操作系统时往往都停留在表层，经常是死记硬背式的学习，根本没有理解达到融会贯通的层面。

这里，我希望自己整理的这套面经针对每个问题都能讲清楚前因后果，串起相关的知识点，并做到**知其然并知其所以然**。

另外推荐几本书（后面的文章都是基于这几本书写的笔记）

1. 《现代操作系统原理与实现》
2. 《Linux内核设计与实现》
3. 《Linux/UNIX系统编程手册》
4. 《Linux多线程服务端编程——使用muduo C++网络库》
5. 小林coding的 《图解系统》：https://xiaolincoding.com/os/

扎扎实实看完上面的几本书，相信对 OS 的理解会有一个质的提升。

## 一、进程与线程

### Q：谈谈你对进程、线程和协程的理解

#### why？为什么会有进程

现代操作系统需要运行各种各样的程序，为了管理这些程序的运行，操作系统提出了进程的抽象：每个进程都对应于一个运行中的程序。

有了进程的抽象后，操作系统就好像是独占了整个 CPU，不用再去考虑何时把 CPU 让给其他的应用程序。（进程的管理、CPU 的分配等任务都交给了OS） 

#### what？进程是什么

我们编写的代码只是一个存储在硬盘上的静态文件，通过编译后就会生成二进制可执行文件，当我们运行它之后，它就会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个 **运行中的程序就被称为「进程」**

----

#### why？为什么会有线程（明明已经有了进程）

随着硬件技术的发展，计算机拥有了更多的 CPU 核心，程序的并行度提高，进程显得比较笨重。

体现在以下方面：

1. 创建进程的开销比较大，需要完成创建独立的地址空间、载入数据和代码段、初始化堆等步骤；
2. 由于进程拥有独立的虚拟地址空间，在进程间进行数据共享和同步比较麻烦，一般只能基于共享虚拟内存页（粒度较粗） 或者 基于进程间通信（开销高）；

因此，OS 的设计人员在进程内部引入了可以独立执行的单元：线程。

**举个例子：**

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204101743105.png" alt="image-20220410174329028" style="zoom:67%;" />

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204101743396.png" alt="image-20220410174357342" style="zoom: 67%;" />

#### what？什么是线程

**线程是进程当中的一条执行流程。**在 Linux 中实现线程的机制非常独特。从内核的角度来说，并没有线程这个概念，Linux 把所有的线程都当作进程来实现。特殊点在于，线程（特殊的进程）与其他进程共享某些资源。

在同一个进程内，多个线程可以共享除寄存器和栈之外的资源，如代码段、数据段、打开的文件等等。

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204122257888.jpg" alt="img" style="zoom: 33%;" />

#### How？线程的优缺点

优点：

- 一个进程中可以同时存在多个线程；
- 各个线程之间可以并发执行；
- 各个线程之间可以共享地址空间等资源。

缺点：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）。

那么，对于游戏的用户设计，就不应该使用多线程的方式，否则一个用户挂了，会影响其他同在一个进程中的线程。

----

#### why？有了线程，为什么还要有协程

随着计算机的发展，应用程序越来越复杂，每个线程各司其职。与操作系统调度器相比，应用程序对线程的执行状态更加了解，因此可能做出更优的调度决策。

另一方面，用户态线程更加轻量级，比内核态线程的创建和切换的开销要小得多，因此更多的使用用户态线程有利于整个系统的可扩展性。

所以就有了协程的概念，协程是用户态的轻量级线程。

#### what？对协程的一些理解

协程的切换都是直接在用户态完成的，不需要操作系统的参与，也不受调度器的控制，这个过程中会减少很多系统开销，从而可以达到很好的性能。

另外，协程使用合作式多任务处理的调度机制来切换上下文，不同与进程、线程的抢占式多任务处理。

#### 加餐

> 转自：https://www.yuque.com/ouweibin/interview/aia9qv#95f4886c 标题：进程、线程、协程 

子程序，或者称为函数，在所有语言中都是层级调用，比如 A 调用 B，B 在执行过程中又调用了 C，C 执行完毕返回，B 执行完毕返回，最后是 A 执行完毕。  所以，子程序调用是通过栈实现的，**一个线程就是执行一个子程序**。

子程序的调用总是一个入口，一次返回，调用顺序是明确的。

而协程的调用和子程序不同：协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行（类似于 CPU 的中断）。

**协程的特点在于一个线程执行，和多线程相比，有何优势？** 

- 最大的优势是**协程有极高的执行效率**：协程的切换完全由程序自身控制，因此，没有线程切换的开销，和多线程相比，线程的数量越多，协程的性能优势就越明显；（PS：？？？？？这里不理解 “和多线程相比，线程的数量越多”，多线程和n个单个线程还有什么区别吗？等我复习完多线程的内容也许会有答案？？？？？）
- 第二大优势就是**不需要多线程的锁机制**：因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不需要加锁，只需要判断状态就好，所以执行效率比多线程高很多。

**因为协程是一个线程执行，那么怎么利用多核 CPU 呢？**

- 最简单的办法就是 **多线程 + 协程**，既充分利用多核，又充分发挥协程的高效率，可以获得极高的性能；
- Python 对协程的支持还非常有限，用在 generator 中的 yield 可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。（PS：？？？？？不懂 python 呀？？？？）



### Q：进程与线程的区别与联系

- 进程是操作系统资源（包括内存、打开的文件等）分配的基本单位，而线程是 CPU 调度的基本单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源（寄存器和栈）；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样可以状态间的相互转换；
- 线程能够减少并发执行时间和空间开销

线程相比进程能减少开销，体现在：

- 线程创建快（进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们）
- 线程终止时间比进程快（因为相比之下线程释放的资源会少很多）
- 同一进程内线程切换比进程更快（线程具有相同的地址空间，这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的）
- 线程之间传输数据效率更高（因为同一进程的各个线程间共享内存和文件资源，那么在数据传输的时候就不需要经过内核了）

综上，不管是时间效率还是空间效率，线程都比进程更优秀。



### Q：为什么有了进程，还要有线程呢？

> **Q：谈谈你对进程、线程和协程的理解** 已经解释了。

### Q：一个进程可以创建多少个线程，和什么有关？如何创建？

> 小林的文章：https://xiaolincoding.com/os/4_process/create_thread_max.html

先说结论，

- 32 位系统，用户态的虚拟空间只有 3G，如果创建线程时分配的栈空间是 8M，那么一个进程最多只能创建 300 个左右的线程；
- 64 位系统，用户态的虚拟空间大到有 128T，理论上不会受虚拟内存大小的限制，而会受到系统参数或性能限制。

-----

在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常⻅的 32 位和 64 位系统，如下所示：

![image-20220411170815342](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204111708391.png)

可以看到：

- 32 位系统的内核空间占 1G，位于最高处，剩下的 3G 是用户空间；
- 64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的

那么，**一个进程最多可以创建多少个线程？**

这个问题和两个东西有关：

- **进程的虚拟内存空间上限**：因为每创建一个线程，OS 需要为其分配一个栈空间。线程数量越多，所需的栈空间就越大，那么虚拟内存就被占用的越多；
- **系统参数限制**：虽然 Linux 并没有内核参数来控制单个进程创建的最大线程个数，但是有系统级别的参数来控制整个系统的最大线程个数。

> 下面这三个内核参数的大小，都会影响创建线程的上限：
>
> - ***/proc/sys/kernel/threads-max***，表示系统支持的最大线程数；
> - ***/proc/sys/kernel/pid_max***，表示系统全局的 PID 号数值的限制，每一个进程或线程都有 ID，ID 的值超过这个数，进程或线程就会创建失败；
> - ***/proc/sys/vm/max_map_count***，表示限制一个进程可以拥有的VMA(虚拟内存区域)的数量。
>
> 我们通过 `top -H` 命令，可以查看当前系统的线程数

我们可以执行 `ulimit -a` 这条命令，查看进程创建线程时默认分配的栈空间大小

![image-20220411173622330](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204111736372.png)

在我的这台 32 位的服务器上，默认分配给线程的栈空间大小为 8M。

那么按照我的服务器来计算的话，最多可以创建 384 个（3G/8M）线程。（当然实际上线程总数肯定小于 384 个，因为用户空间还要存储其他资源）



### Q：进程的状态转换

进程有五种基本状态，即新生状态、就绪状态、运行状态、阻塞状态和终止状态

- 新生状态：表示一个进程刚被创建出来，还未完成初始化；
- 就绪状态：表示该进程可以被 CPU 调度执行，但还未被调度器选择；
- 运行状态：表示进程正在 CPU 上运行。当一个进程执行一段时间后，调度器可以选择中断它的执行并重新将其放回调度队列中，此时进程又会迁移至就绪状态。如果进程需要等待某些外部事件，他就会放弃 CPU 并迁移至阻塞状态。当进程运行结束，它就会迁移至终止状态；
- 阻塞状态：表示进程需要等待某些外部事件（如某个I/O请求的完成），暂时无法被调度；
- 终止状态：表示进程已经完成了执行，且不会再被调度。

![image-20220411155101883](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204111551950.png)

#### 加餐

查看进程：`ps aux / ajx`

- a：显示终端上的所有进程，包括其他用户的进程
- u：显示进程的详细信息
- j：列出与作业控制相关的信息
- x：显示没有控制终端的进程

STAT参数意义：

- D：不可中断 Uninterruptible（usualy IO）
- R：正在运行，或在队列中的进程
- S：处于休眠状态
- s：包含子进程
- T：停止或被追踪
- Z：僵尸进程
- W：进入内存交换（从内核2.6开始无效）
- X：死掉的进程
- <：高优先级
- N：低优先级
- +：位于前台的进程

实时显示进程状态：`top`

可以在使用 top 命令时加上 `-d` 来指定显示信息更新的时间间隔，在 top 命令执行后，可以按以下按键对显示的结果进行排序：

- M：根据内存使用量排序
- P：根据 CPU 占有率排序
- T：根据进程运行时间长短排序
- U：根据用户名来筛选进程
- K：输入指定的 PID 杀死进程

杀死进程：

```shell
kill [-signal] pid
kill -SIGKILL 进程ID
kill -9 进程ID		# -9是SIGKILL信号，能强制杀死进程
killall name 		# 根据进程名杀死进程
kill -l 			# 列出所有信号
```



### Q：（进程 / 线程）阻塞、挂起、睡眠的区别

> 我是看的这篇文章：https://chowdera.com/2021/12/20211204040533059s.html

共同本质：都是正在执行的 进程/线程 由于某些原因 主动/被动 释放 CPU，暂停执行。

#### 阻塞（被动）

解释：进程/线程 被动暂停执行，**阻塞的进程仍处于内存中**。OS 把 CPU 分配给另一个就绪进程，让被暂停的进程处于阻塞状态。

阻塞恢复：在需要等待的资源得到满足后，就会重新进入就绪状态等待被调度。

阻塞原因：

- 进程：由于进程提出了系统服务请求（如 I/O 操作），但因为某些原因未得到操作系统的立即响应；
- 线程：线程锁问题。

#### 挂起（主动）

解释：用户主动暂停执行 进程/线程，**被挂起的进程会换出到外存（磁盘）中。**

挂起恢复：需要用户主动控制，挂起时线程不会释放对象锁。

挂起原因：

- 终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂停使自己的程序静止下来。这样会使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度。
-  父进程的请求。有时父进程希望挂起自己的某个子进程，以便考察和修改子进程，或者协调各子进程间的活动。
-  负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。
-  操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。
- 对换的需要。为了缓和内存紧张的情况，将内存中处于阻塞状态的进程换至外存上。

#### 睡眠（主动）

解释：用户主动暂停执行 进程/线程，**睡眠了的 进程/线程 仍处于内存中。**

睡眠恢复：自动完成，睡眠时间到了则恢复到就绪态，睡眠时线程不会释放对象锁。

示例：`thread.sleep(1000);` 将线程睡眠一秒。



### Q：进程终止的几种方式

有 8 种方式使进程终止，其中 5 种为正常终止，分别为：

1. 从 main 函数返回；
2. 调用 exit；
3. 调用 _exit 或 _Exit；
4. 最后一个线程从其启动例程返回；
5. 从最后一个线程调用调用 pthread_exit；

异常终止有 3 种方式，分别为：

1. 调用 abort；
2. 接到一个信号；
3. 最后一个线程对取消请求做出响应。



### Q：进程的调度算法有哪些？

> 小林的文章：https://xiaolincoding.com/os/5_schedule/schedule.html

- 先来先服务调度算法

  > CPU 每次从就绪队列选择最先进入队列的进程，一直运行，直到进程退出或被阻塞，才继续从队列中选择第一个进程接着运行。
  >
  > 评价：对长作业有利，适用于 CPU 繁忙型作业的系统，不适用于 I/O 繁忙型作业的系统。

- 最短作业优先调度算法

  > CPU 优先选择运行时间最短的进程来运行，有助于提高系统的吞吐量。
  >
  > 评价：对长作业不利，很容易造成长作业永远运行的极端现象。

- 高响应比优先调度算法

  > 每次进行进程调度时，先计算「响应比优先级」，然后选择「响应比优先级」最高的进程运行。
  >
  > 「响应比优先级」的计算公式：**优先级 = （等待时间 + 要求服务时间）/ 要求服务时间**

- 时间片轮转调度算法

  > 最古老、最简单、最公平且使用最广的算法就是 时间片轮转调度算法。
  >
  > 每个进程被分配一个时间段（称为时间片），即允许该进程在该时间段中运行。
  >
  > 注意：
  >
  > 时间片的长度是一个很关键的点：
  >
  > - 如果时间片设置过短会导致过多的进程进行上下文切换，从而降低了 CPU 效率；
  > - 如果设置太长又可能引起对短作业进程的响应时间变长。
  >
  > 通常时间片设为 `20ms ~ 50ms` 是一个比较合理的折中值。

- 最高优先级调度算法

  > 多用户计算机系统希望调度有优先级，CPU 每次从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级调度算法。
  >
  > 进程的优先级可以分为静态优先级和动态优先级。并且该算法有两种处理优先级高的方法，非抢占式和抢占式。
  >
  > 评价：可能导致低优先级的进程永远不会运行。

- 多级反馈队列调度算法

  > 多级反馈队列调度算法时「时间片轮转算法」和「最高优先级算法」的综合和发展。
  >
  > 1. 它设置了多个队列，并赋予每个队列不同的优先级，**队列的优先级从高到低**，同时**优先级高的时间片越短**；
  > 2. 新的进程会被放到第一级队列的末尾，按照先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入为第二级队列的末尾，以此类推，直至完成；
  > 3. 当较高优先级的队列为空时，CPU 才调度较低优先级的队列中的进程。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行。
  >
  > 评价：该算法很好的兼顾了长短作业，同时有较高的响应时间。



### Q：对守护进程、僵尸进程和孤儿进程的理解

#### 守护进程

守护进程是一种在后台执行的电脑程序，以进程的形式被初始化。守护进程程序的名称通常以字母 “d” 结尾。

通常，守护进程没有任何存在的父进程（即`PPID = 1`），且在 UNIX 系统进程层级中直接位于 init 之下。（守护进程如何产生：对一个子进程执行 fork，然后使其父进程立即终止，使得这个子进程能在 init 下运行）

系统通常在启动时一同启动守护进程。守护进程为系统的 网络请求、硬件活动进行响应，或其它通过某些任务对其他应用程序的请求进行回应提供支持。

#### 孤儿进程

##### what？什么是孤儿进程

孤儿进程指在其父进程执行完成或被终止仍继续运行的一类程序。任何孤儿进程产生时都会立即被系统进程 init 或 systemd 自动接收为子进程，因此孤儿进程并没有什么危害。

拓展：因为父进程终止或崩溃都会导致对应的子进程称为孤儿进程，所以多数类 UNIX 系统都引入了进程组以防止产生孤儿进程：在父进程终止后，用户的 Shell 会将父进程所在的进程组标为 “孤儿进程组”，并向该终止的进程下所有的子进程发出 SIGHUP 信号，以试图结束它们的运行，使得避免子进程继续以 “孤儿进程” 的身份运行。

##### where？应用

有的时候用户会刻意使进程成为孤儿进程，这样就会让它跟用户会话脱钩，并转至后台运行。常用于启动需要长时间运行的进程，即守护进程。（命令 `nohup` 也可以完成这一操作）

##### 远程过程调用会不会产生孤儿进程？

会。

举个例子，若客户端进程在发起请求后突然崩溃，且对应的服务器端进程仍在运行，则该服务器端进程就会成为孤儿进程。这样的孤儿进程会浪费服务器的资源，甚至存在耗尽资源的潜在危险，有以下解决方案：

1. 终止机制：强制杀死孤儿进程（最常用的手段）
2. 再生机制：服务器在指定时间内查找调用的客户端，若找不到直接杀死孤儿进程；
3. 超时机制：给每个进程指定一个确定的运行时间，若超时仍未完成则强制终止。若有需要，也可以让进程在指定时间耗尽之前申请延时。

#### 僵尸进程

##### what？什么是僵尸进程

一个子进程的进程控制块在它退出时不会释放，**只有当父进程通过 wait 或 waitpid 获取了子进程信息后才会释放**。如果子进程退出，而父进程并没有调用 wait 或 waitpid，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵尸进程。 

僵尸进程通过 ps 命令显示出来的状态为 Z。

拓展：当一个子进程退出时，系统会给父进程发送 SIGCHLD 信号，父进程对其默认忽略。（要响应，就要父进程通过 wait 或 waitpid 调用来响应子进程的终止）

##### 如何避免僵尸进程？如何处理？

1. 终止父进程（一般不用）
   严格来说，僵尸进程不是问题的根源，罪魁祸首是产生大量僵尸进程的父进程。因此，我们可以直接消灭父进程（通过 kill 发送 SIGTERM 或 SIGKILL 信号），这时僵尸进程会变成孤儿进程，由 init 充当父进程并回收资源。
2. 父进程用 wait 或 waitpid 去回收资源（方案不好）
   缺点：会导致父进程处于阻塞状态，而父进程可能还有其他任务要做，不能阻塞在这里。
3. 通过信号机制，在处理函数中调用 wait，回收资源（✔✔✔）
   通过信号机制，子进程退出时向父进程发送 SIGCHLD 信号，父进程调用 `signal(SIGCHLD, sig_child)` 去处理 SIGCHLD 信号，在信号处理函数 `sig_child()` 中调用 wait 处理僵尸进程。这时，父进程可以继续做其他任务，不用阻塞等待。
4. 进程 fork 两次并杀死一级子进程，使二级子进程成为孤儿进程而被 init 所收养。（✔✔✔）

##### 浅谈 wait 和 waitpid 接口

- 回收进程（1）：`pid_t wait(int* status)`
  status：指向子进程结束状态值
  - 父进程一旦调用 wait()，就会立即阻塞自己，wait()自动分析某个子进程是否已经退出，如果找到僵尸进程就会负责收集和销毁，如果没有找到就一直阻塞在这里

- 回收进程（2）：`pid_t waitpid(pid_t pid, int *status, int options)`
  - 返回值：返回pid：返回收集的子进程id；返回-1：出错；返回0：没有被收集的子进程 
  - pid：子进程识别码，控制等待哪些子进程 
    1.  pid < -1，等待进程组识别码为 pid 绝对值的任何进程 
    2.  pid = -1，等待任何子进程 
    3.  pid = 0，等待进程组识别码与目前进程相同的任何子进程 
    4.  pid > 0，等待任何子进程识别码为 pid 的子进程 
  - status：指向返回码的指针。 
  - options：选项决定父进程调用 waitpid 后的状态 
    1. options = WNOHANG，即使没有子进程退出也会立即返回 
    2.  options = WUNYRACED，子进程进入暂停马上返回，但结束状态不予理会 

##### kill -9 无法强制杀死进程的原因

`kill -9` 发送 SIGKILL 信号，对以下两种情况不起作用：

- 该进程处于 Zombie 状态，此时进程已经释放了所有资源，但还未得到其父进程的确认。
- 该进程处于内核态且在等待不可获得的资源。处于内核态的进程忽略所有信号处理（只能通过重启系统实现）（PS：？？？？不太理解）




### Q：如何避免僵尸进程？以及处理僵尸进程的两种经典方法

> **Q：对守护进程、僵尸进程和孤儿进程的理解** 已回答

### Q：fork进程时的底层机制，和vfork的不同点？

#### what？fork 和 vfork 是什么

都是拿来创建进程的。

```c
#include <unistd.h>
pid_t fork(void);
// 返回值：子进程返回0，父进程返回子进程ID；若出错，返回-1

#include <unistd.h>
pid_t vfork(void);
// 返回值：子进程返回0，父进程返回子进程ID；若出错，返回-1
```

使 fork 失败的两个主要原因：

1. 当前系统中的进程总数已到达系统规定的上限
2. 进程数量超过了该用户对它设置的限制

#### fork 和 vfork 的底层机制

Linux 通过 clone() 系统调用实现 fork()。这个调用通过一系列的参数标志指明父子进程需要共享的资源。

1. fork()、vfork() 和 _clone() 库函数都根据各自需要的参数标志去调用 clone()；

2. 然后 clone() 再去调用 do_fork()；

3. do_fork() 完成创建中的大部分工作（定义在 `kernel/fork.c` 文件中）；

4. 然后该函数再调用 copy_process() 函数；

   > 如果 copy_process() 函数返回成功，新创建的子进程将被唤醒并让其投入运行中。

5. 然后让进程开始运行。

#### fork 和 vfork 的区别

1. vfork() 不拷贝父进程的页表项，而是共享父进程的内存，直至其成功执行 exec() 或调用 _exit() 退出；
2. 在子进程调用 exec() 或 _exit() 之前，将会阻塞父进程。

#### 加餐

fork 系统调用的全过程图：

![ad58a5ae-532c-4ef3-a09c-a99ff3cabf39](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204121957727.jpg)



### Q：进程、线程在上下文切换的流程分别是什么？

#### 进程的上下文切换

**什么是进程的上下文？**进程的上下文包括进程运行时的寄存器状态，其能够用于保存和恢复一个进程在处理器上运行的状态。当操作系统需要切换当前执行的进程时，就会使用上下文切换机制。

**产生条件：**当 进程 由于中断或者系统调用进入内核之后，操作系统就可以进行上下文切换。

**切换过程：** 

1. 首先，操作系统会将 进程1 的上下文保存在其对应的 PCB 中；
2. 之后，如果调度器选择 进程2 作为下一个执行的进程，操作系统会取出 进程2 对应的 PCB 中的上下文，将其中的寄存器值恢复到对应的寄存器中；
3. 最后，操作系统会回到用户态，继续 进程2 的执行。

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204122049784.png" alt="image-20220412204926636" style="zoom:50%;" />

**发生进程上下文切换的场景：**

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片被耗尽了，进程就从运行状态变为就绪状态，然后系统从就绪队列选择另一个进程运行；
- 进程再系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这时候进程也会被挂起，并由系统调度其他进程运行；
- 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

总之，就是哪里有进程切换，那里就会发生进程的上下文切换。

#### 线程的上下文切换

**什么是线程的上下文：**在实际的硬件中，线程的上下文主要指当前处理器中大部分寄存器的值，包括：程序计数器、通用寄存器和特殊寄存器。

在线程切换的时候，操作系统会将线程的上下文保存在该线程对应的内核态线程的 TCB 里。

- 当两个线程不属于同一个进程时，切换的过程跟进程的上下文切换一样；
- 当两个线程属于同一个进程时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

相比之下，线程的上下文切换开销要比进程的上下文切换小得多。



### Q：线程间到底共享了哪些进程资源？

> 其实在 **Q：谈谈你对进程、线程和协程的理解** 里面已经简单谈过了，另外可以看看这篇文章：https://cloud.tencent.com/developer/article/1768025，强烈推荐！

 线程共享进程地址空间中除线程上下文信息中的所有内容，有代码区、数据区、堆区和栈区。

下面来逐一分析：

**代码区：**代码区保存的是我们编译后的可执行二进制代码，**这就意味着程序中的任何一个函数都可以放到线程中去执行，不存在某个函数只能被特定线程执行的情况**。

**数据区：**存放的就是所谓的全局变量，在程序员运行期间，**数据区中的全局变量有且仅有一个实例，所有的线程都可以访问到该全局变量**。

> 注意：在C语言中还有一类特殊的 “全局变量”，那就是用static关键词修饰过的变量，如：
>
> ```c
> void func() { 
>     static int a = 10; 
> }
> ```
>
> 虽然变量 a 定义在函数内部，但变量 a 依然具有全局变量的特性，也就说变量 a 在初始化的时候被放在进程地址空间的数据区域，即使函数执行完后该变量依然存在。

**堆区：**在 C/C++ 中用 malloc 或者 new 出来的数据就存放在这个区域，我们**只要知道了变量的地址（即指针），任何一个线程都可以访问指针指向的数据**，因此堆区也是线程共享的属于进程的资源。

**栈区：**从线程这个抽象的概念上来说，栈区是线程私有的，然而从实际的实现上看，**栈区属于线程私有这一规则并没有严格遵守**。

因为不像进程地址空间之间的严格隔离，线程的栈区没有严格的隔离机制来保护，因此如果一个线程能拿到来自另一个线程栈帧上的指针，**那么该线程就可以改变另一个线程的栈区**，也就是说这些线程可以任意修改本属于另一个线程栈区中的变量。

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204130120717.png" alt="image-20220413012003655" style="zoom: 67%;" />

从某种程度上给了程序员极大的便利，但同时，这也会导致极其难以排查到的bug。

**动态链接库：**如果一个程序是动态链接生成的，**那么其地址空间中有一部分包含的就是动态链接库**，否则程序就运行不起来了，这一部分的地址空间也是被所有线程所共享的。

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204130125197.png" alt="image-20220413012532134" style="zoom:67%;" />

**文件：**如果程序在运行过程中打开了一些文件，那么进程地址空间中还保存有打开的文件信息，进程打开的文件也可以被所有的线程使用，这也属于线程间的共享资源。



### Q：exit 和 _exit的区别？

exit 和 _exit 都是用来终止进程的。

```c
#include <unistd.h>
void _exit(int status);
```

调用 _exit() 的程序总会成功终止。但程序一般不会直接调用 _exit()，而是调用库函数 exit()，它会在调用 _exit() 前执行各种动作。

```c
#include <stdlib.h>
void exit(int status);
```

exit() 的执行动作：

1. 调用退出处理程序（通过  atexit() 和 on_exit() 注册的函数，其执行顺序与注册顺序相反）；
2. 刷新 stdio 流缓冲区；
3. 使用由 status 提供的值执行 _exit() 系统调用。

由此可以看到，exit() 是对 _exit() 的一层封装。

#### 加餐

**什么是退出处理程序？**

why？为什么会有退出处理程序：有时应用程序需要在进程终止时自动执行一些操作。如，进程使用了某应用程序库，那么在进程终止前该库需要自动执行一些清理工作，但是库本身对进程何时、如何退出并没有控制权，也无法要求主程序在退出前调用库中特有的清理函数。所以就有了 退出处理程序。

what？退出处理程序是什么：一个由程序设计者提供的函数，可用于进程生命周期的任意时间点注册，并会在该进程调用 exit() 正常终止时自动执行。But，如果直接程序直接调用 _exit() 或因信号而异常终止，则不会调用。

GNU C语言函数库提供两种方式来注册退出处理程序：

1. 使用 atexit() 函数

   ```c
   #include <stdlib.h>
   int atexit(void (*func)(void));
   // 成功：返回0；错误：返回非零值
   ```

   缺点：在由 atexit() 注册的退出处理程序中会受到两种限制：1、退出处理程序在执行时无法获知传递给 exit() 的状态（有时知道状态是必要的，如根据进程是否成功退出而执行不同的动作）；2、无法给退出处理程序指定参数（知道了参数，退出处理程序就可以根据传入参数的不同执行不同的动作，或者使用不同的参数多次注册同一函数）

2. 针对 atexit() 函数的限制，glibc 提供了一个非标准的替代方法：on_exit() 函数

   ```c
   #include <stdlib.h>
   int on_exit(void (*func)(int, void*), void* arg);
   // 成功：返回0；错误：返回非零值
   ```

   注意：虽然 on_exit() 比 atexit() 更加灵活，但是对于要保障移植性的程序来说，还是要避免使用。



## 二、进程间通信和同步

### Q：进程间的通信方式有哪些？

先说结论：有管道、消息队列、共享内存、信号量、信号、socket。

**由于每个进程的的用户地址空间都是独立的，一般而言是无法进程相互访问，但内核空间使每个进程所共享的，所以进程间要通信，必须通过内核。**

#### 管道

##### what？

**什么是管道？** 管道是两个进程间的一条通道，一端负责投递，另一端负责接收。因此，管道是单向的 IPC，要想实现双向通信，就要创建两个管道。

对于管道，通常是以 FIFO 缓冲区来管理数据的。也就是说，所谓的管道就是内核中的一串缓存。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。

**管道的分类？** 管道又分为 匿名管道 和 命名管道。主要的区别在于他们的创建方式。

##### 匿名管道

举个例子：

```shell
ps aux | grep target
# 查看当前是否有关键字 target 相关的进程在运行
```

这里其实是两个命令，通过 Shell 的管道符号 `|` ，将第一个命令的输出投递到一个管道中，而管道对应的出口是第二个命令来输入。

匿名管道的创建：

```c
#include <unistd.h>
int pipe(int fd[2]);
// fd[2]为两个文件描述符，fd[0]：读端描述符；fd[1]：写端描述符
```

管道具体是如何进行两进程间的通信的呢？

通常，管道都是要结合 fork 来使用，创建的子进程会复制父进程的文件描述符，这样就做到了两个进程各有两个「 `fd[0]` 与 `fd[1]`」，两个进程就可以通过各自的 fd 写入和读取同一个管道文件实现跨进程通信。

![image-20220414110139503](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141101568.png)

注意：在 fork 完成后，父子进程都会同时拥有管道的两端，此时需要父子进程主动关闭多余的端口，否则可能导致通信出错。通常的做法：

- 父进程关闭读取的 fd[0]，只保留写入的 fd[1]；
- 子进程关闭写入的 fd[1]，只保留读取的 fd[0]；

![image-20220414110400208](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141104258.png)

通信范围：这种方式对于父子进程等有着创建关系的进程间通信比较方便，但对于两个关系比较远的进程不太适用。

##### 命名管道

命名管道是通过 `mkfifo` 命令来创建的，并且需要指定管道名字：

```shell
mkfifo myPipe
```

接下来，往 myPipe 这个管道写入数据：

```shell
echo "hello" > myPipe	# 将数据写进管道
						# 停住了...
```

操作之后会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。

于是，我们执行另外一个命令来读取这个管道里的数据：

```shell
cat < myPipe	# 读取管道中的数据
hello
```

可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。

通信范围：因为提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。因此它可以在任意两个进程间通信。

##### 管道的优缺点

通过上面的介绍，可以看到，**管道这种通信方式效率低，不适合进程间频繁地交换数据**。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。

##### 加餐

在还没有数据写入时，拿着输出端的进程就开始尝试读取数据，此时会有两种情况：

1. 如果系统发现当前没有任何进程有这个管道的写端口，就会看到 EOF(End-of-File)；
2. 否则，输出端的进程就会阻塞在这个系统调用上，知道接收到数据。

这里之所以存在第一种情况，是因为管道的两个端口在 UNIX 系列的内核中是以两个独立的文件描述符存在的，写端口可能被进程主动关闭了。

对于第二种情况，进程可以通过配置非阻塞选项来避免阻塞。



#### 消息队列

##### why？为什么需要消息队列

前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。对于这个问题，消息队列的通信模式可以解决。

举个例子，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

##### what？消息队列的结构是什么样的

消息队列在内核中是以链表队列的形式存在，如下图所示。

<img src="https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141148605.png" alt="image-20220414114820181" style="zoom: 25%;" />

在消息的结构体中，除了 “下一个” 指针之外， 就是消息的内容。消息的内容包含两部分：类型 和 数据。类型是用户态程序为每个消息指定的；数据是一段内存数据，和管道中的字节流相似。

在消息队列的设计中，内核不需要知道类型的语义，仅仅是保存，以及基于类型进行简单的查找。

对于消息队列，一旦一个队列被创建，除非内核重新启动或者该队列被主动删除，否则消息队列的数据都会被保留。

#### 消息队列的优缺点

先说结论，**一是消息体有大小限制，二是通信不及时**。

1. 在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。
   在 Linux 内核中，会有两个宏定义 `MSGMAX` 和 `MSGMNB`，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。
2. 消息在用户态和内核态之间传递时，会有拷贝的开销。
   因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。



#### 共享内存

##### why？为什么有共享内存，解决了什么问题

消息队列的读取和写入过程，都会有发生用户态与内核态之间的消息拷贝过程。而共享内存就很好的解决了这一问题。

共享内存的思路其实就是内核为需要通信的进程建立共享区域。一旦共享区域完成建立，内核就基本上不需要参与进程间通信，大大提高了性能。

##### 什么是共享内存

现代操作系统对于内存管理，采用的是虚拟内存技术，每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。

而**共享内存，就是拿出一块内存空间，允许一个或多个进程所在的虚拟内存空间映射过去，从而实现通信。**这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。

![image-20220414151239058](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141512118.png)



#### 信号量

##### why?为什么需要信号量

用了共享内存通信方式后，又带来了新的问题：如果多个进程同时修改同一个共享内存，很有可能会发生冲突（比如，两个进程同时写入一个地址，那先写的那个进程会发现内容被别人覆盖）。

为了防止多进程竞争共享资源而造成数据错乱，所以需要保护机制，使得共享资源在任意时刻只能被一个进程访问。信号量就实现了这一保护机制。

##### what？

和消息队列这类明确的 “传递消息” 的方案不同，信号量其实是一个整型计数器，在实际使用中主要用于实现进程间的互斥和同步。

信号量的主要操作是两个原语：P 和 V。

- P 表示尝试一个操作，这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
- V 操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；

P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。

##### how？实际应用示例

**同步信号量：**

对于两个进程 A 和 B，我们希望在 A 执行完相关代码后，B 再执行（如，A 负责生产数据，B 负责读取数据）。那么此时它们可以共享一个信号量，使信号量初始化为 `0`。

A 进程会在执行完代码之后，执行一个对共享信号量的 V 操作，而 B 进程会在执行代码前，执行一个对共享信号量的 P 操作。

- 如果内核先调度了进程 B，使其 P 操作最先发生，此时会导致信号量的结果为 -1，而这是不被允许的，因此内核将会阻塞 B 进程。
- 当 A 进程执行完自己的代码后，执行 V 操作，此时会将信号量的值更新为 0。同时，内核会发现此时 B 的 P 操作已经可以成功了，因此内核会唤醒 B，并执行 B 的操作。

![image-20220414185932450](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141859507.png)

**互斥信号量**

对于两个进程 A 和 B，我们希望两个进程互斥访问共享内存，我们可以初始化信号量为 `1`。

![image-20220414191047617](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141910668.png)

- 进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。
- 若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。
- 直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。

因此：

- 同步信号量：信号初始化为 `0`
- 互斥信号量：信号初始化为 `1`



#### 信号

##### why？为什么需要信号

前面说的管道、消息队列、共享内存等方式都是在常规状态下的工作模式，主要关注的是数据传输设计，而对于异常情况下的工作模式，就需要用「信号」的方式通知进程。

**信号和信号量对比：**

- 信号量也有通知能力，但需要进程主动去查询计数器状态或陷入阻塞状态（来等待通知）。
- 使用信号，一个进程可以随时发送一个事件到特定的进程、线程或进程组等，并且接收事件的进程不需要阻塞等待该事件，内核会帮助其切换到对应的处理函数中响应信号事件，并在处理完成后恢复之前的上下文。

##### what？信号的基本介绍

信号是进程间通信机制中**唯一的异步通信机制**，它传递的信息很短，只有一个编号。在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 `kill -l` 命令，查看所有的信号：

```shell
$ kill -l
 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
63) SIGRTMAX-1  64) SIGRTMAX
```

信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）：

运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如

- Ctrl+C 产生 `SIGINT` 信号，表示终止该进程；
- Ctrl+Z 产生 `SIGTSTP` 信号，表示停止该进程，但还未结束。

如果进程在后台运行，可以通过 `kill` 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程。

##### 信号的响应和处理

信号得到处理的时机通常是内核执行完异常、中断、系统调用等返回到用户态的时刻。

内核对信号的处理一般有三种方式：

1. 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。
2. 捕捉信号。我们可以为信号定义一个信号处理函数，当信号发生时，我们就执行相应的信号处理函数。
3. 执行内核默认处理函数。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。



#### socket

##### why？为什么需要套接字通信

前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，要想跨网络与不同主机上的进程之间通信，就需要 socket 通信。

##### what？

socket 是一种既可用于本地，又可跨网络使用的通信机制。

Linux 中创建 socket 的系统调用：

```c
#include <sys/socket.h>
int socket(int domain, int type, int protocal);
/*三个参数分别代表：
	domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；
	type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；
	protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；
*/	
```

##### socket 通信模型

> **针对 TCP 协议通信的 socket 编程模型**：socket 类型是 AF_INET 和 SOCK_STREAM

![image-20220414234254719](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204142342823.png)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

这里需要注意的是，服务端调用 `accept` 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。

所以，监听的 socket 和真正用来传送数据的 socket，是「**两个**」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。

> **针对 UDP 协议通信的 socket 编程模型**：socket 类型是 AF_INET 和 SOCK_DGRAM

![image-20220414234452202](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204142344258.png)

UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。

对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。

另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。

> **针对本地进程间通信的 socket 编程模型**

- 对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。
- 对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。
- 另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是**绑定一个本地文件**，这也就是它们之间的最大区别。



#### 加餐

几种 IPC 通信方式对比

![image-20220414120108901](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204141201084.png)

**匿名管道** 顾名思义，它没有名字标识，匿名管道是特殊文件只存在于内存，没有存在于文件系统中，shell 命令中的「`|`」竖线就是匿名管道，通信的数据是**无格式的流并且大小受限**，通信的方式是**单向**的，数据只能在一个方向上流动，如果要双向通信，需要创建两个管道，再来**匿名管道是只能用于存在父子关系的进程间通信**，匿名管道的生命周期随着进程创建而建立，随着进程终止而消失。

**命名管道** 突破了匿名管道只能在亲缘关系进程间的通信限制，因为使用命名管道的前提，需要在文件系统创建一个类型为 p 的设备文件，那么毫无关系的进程就可以通过这个设备文件进行通信。另外，不管是匿名管道还是命名管道，进程写入的数据都是**缓存在内核**中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循**先进先出**原则，不支持 lseek 之类的文件定位操作。

**消息队列** 克服了管道通信的数据是无格式的字节流的问题，消息队列实际上是保存在内核的「消息链表」，消息队列的消息体是可以用户自定义的数据类型，发送数据时，会被分成一个一个独立的消息体，当然接收数据时，也要与发送方发送的消息体的数据类型保持一致，这样才能保证读取的数据是正确的。消息队列通信的速度不是最及时的，毕竟**每次数据的写入和读取都需要经过用户态与内核态之间的拷贝过程。**

**共享内存** 可以解决消息队列通信中用户态与内核态之间数据拷贝过程带来的开销，**它直接分配一个共享空间，每个进程都可以直接访问**，就像访问进程自己的空间一样快捷方便，不需要陷入内核态或者系统调用，大大提高了通信的速度，享有**最快**的进程间通信方式之名。但是便捷高效的共享内存通信，**带来新的问题，多进程竞争同个共享资源会造成数据的错乱。**

那么，就需要 **信号量** 来保护共享资源，以确保任何时刻只能有一个进程访问共享资源，这种方式就是互斥访问。**信号量不仅可以实现访问的互斥性，还可以实现进程间的同步**，信号量其实是一个计数器，表示的是资源个数，其值可以通过两个原子操作来控制，分别是 **P 操作和 V 操作**。

与信号量名字很相似的叫 **信号**，它俩名字虽然相似，但功能一点儿都不一样。信号是进程间通信机制中**唯一的异步通信机制**，信号可以在应用进程和内核之间直接交互，内核也可以利用信号来通知用户空间的进程发生了哪些系统事件，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令），一旦有信号发生，**进程有三种方式响应信号 1. 执行默认操作、2. 捕捉信号、3. 忽略信号**。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，这是为了方便我们能在任何时候结束或停止某个进程。

前面说到的通信机制，都是工作于同一台主机，如果**要与不同主机的进程间通信，那么就需要 socket 通信了**。socket 实际上不仅用于不同的主机进程间通信，还可以用于本地主机进程间通信，可根据创建 socket 的类型不同，分为三种常见的通信方式，一个是基于 TCP 协议的通信方式，一个是基于 UDP 协议的通信方式，一个是本地进程间通信方式。



### Q：线程间的通信方式有哪些？

> 注：这一部分内容主要是依照小林哥的文章做的笔记：https://xiaolincoding.com/os/4_process/multithread_sync.html

前言：同个进程下的线程之间都是共享进程的资源，只要是共享变量都可以做到线程间通信，比如全局变量，所以对于线程间关注的不是通信方式，而是关注多线程竞争共享资源的问题，信号量也同样可以在线程间实现互斥与同步：

- 互斥的方式，可保证任意时刻只有一个线程访问共享资源；
- 同步的方式，可保证线程 A 应在线程 B 之前执行。

简单说一下同步和互斥的概念：

所谓同步，就是并发进程 / 线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通消息称为进程 / 线程同步。

而互斥，由于多线程执行操作共享变量的代码段时可能会导致竞争状态，我们要保证任意时刻一个线程在临界区执行，其他线程都被阻止进入，称这种方式为互斥。

为了实现进程 / 线程间正确的协作，主要有以下两种方法：

- 锁：加锁、解锁操作；
- 信号量：P、V操作。

其中，信号量不仅能实现 进程/线程 的互斥，还能方便的实现 进程/线程 同步。

#### 锁

加锁的目的就是保证共享资源在任意时间内，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。

最常用的就是互斥锁，还有很多种不同的锁，比如自旋锁、读写锁、乐观锁、悲观锁等，不同种类的锁适用于不同的场景（因为如果选择了错误的锁，那么在一些高并发的场景下，可能会降低系统的性能，这样用户体验就会非常差）。

> 几种锁的介绍在 **Q：介绍一些几种经典的锁以及应用场景** 中。

#### 条件变量



#### 信号量

##### what？

信号量在不同的线程之间充当信号灯，其根据剩余资源数量控制不同线程的执行或等待。对应的变量是一个整型变量（下面用 sem 表示）。

除了初始化之外，信号量只能通过两个操作来进行更新：

- P 操作（wait）：将 sem 减 1，相减后，如果 `sem < 0`，则 进程/线程 进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
- V 操作（signal）：将 sem 加 1，相加后，如果 `sem <= 0`，唤醒一个等待中的 进程/线程，表面 V 操作不会阻塞。

P 操作用在进入临界区之前，V 操作用在临界区之后，这两个操作必须成对出现。

##### 信号量的实现

```c
// 信号量数据结构
type struct sem_t {
    int sem;	// 资源个数
    queue_t *q;	// 等待队列
} sem_t;

// 初始化信号量
void init(sem_t *s, int sem) {
    s->sem = sem;
    queue_init(s->q);
}

// P 操作
void P(sem_t *s) {
    s->sem--;
    if (s->sem < 0) {
        1. 保留调用线程 CPU 现象;
        2. 将该线程的 TCB 插入到 s 的等待队列中;
        3. 设置该线程为等待状态;
        4. 执行调度程序;
    }
}

// V 操作
void V(sem_t *s) {
    s->sem++;
    if (s->sem <= 0) {
        1. 移出 s 等待队列首元素;
        2. 将该线程的 TCB 插入就绪队列;
        3. 设置该线程为就绪状态;
    }
}
```

PV 操作的函数是由操作系统管理和实现的，所以操作系统已经使得执行 PV 函数时是具有原子性的。

##### how？如何使用 PV 操作

**信号量实现临界区的互斥访问 示例**

为每类共享资源设置一个信号量 `s`，其初值为 `1`，表示该临界资源未被占用。只要把进入临界区的操作置于 `P(s)` 和 `V(s)` 之间，就可以实现 进程/线程 互斥：

![image-20220417003100728](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204170031847.png)

过程：

任何想进入临界区的线程，必先在互斥信号量上执行 P 操作，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。

若此时又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用，因此，第二个线程被阻塞。

并且，直到第一个线程执行 V 操作，释放临界资源而恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。

**信号量实现事件同步 示例**

同步的方式是设置一个信号量，其初值为 `0`。

拿「吃饭 - 做饭」的例子，用代码实现：

```c
semaphore s1 = 0;	// 表示不需要吃饭
semaphore s2 = 0;	// 表示饭还没做完

// 儿子线程函数
void son {
    while (true) {
        肚子饿;
        V(s1);	// 叫妈妈做饭
        P(s2);	// 等待妈妈做完饭
        吃饭;
    }
}

// 妈妈线程函数
void mom {
    while (true) {
        P(s1);	// 询问是否需要做饭
        做饭;
        V(s2);	// 做完饭，通知儿子吃饭
    }
}
```

妈妈一开始询问儿子要不要做饭时，执行的是 `P(s1)` ，相当于询问儿子需不需要吃饭，由于 `s1` 初始值为 0，此时 `s1` 变成 -1，表明儿子不需要吃饭，所以妈妈线程就进入等待状态。

当儿子肚子饿时，执行了 `V(s1)`，使得 `s1` 信号量从 -1 变成 0，表明此时儿子需要吃饭了，于是就唤醒了阻塞中的妈妈线程，妈妈线程就开始做饭。

接着，儿子线程执行了 `P(s2)`，相当于询问妈妈饭做完了吗，由于 `s2` 初始值是 0，则此时 `s2` 变成 -1，说明妈妈还没做完饭，儿子线程就等待状态。

最后，妈妈终于做完饭了，于是执行 `V(s2)`，`s2` 信号量从 -1 变回了 0，于是就唤醒等待中的儿子线程，唤醒后，儿子线程就可以进行吃饭了。



#### 加餐

什么是原子操作？

原子操作指的是不可被打断的一个或一系列操作。即要么这一系列指令都执行完成，要么这一系列指令一条都没有执行，不会出现执行到一半的状态。

最常见的原子操作包括比较与置换（Compare-Add-Swap，CAS）、拿取并累加（Fetch-Add-Add，FAA）等。

下面用 C 语言分别展示两种原子操作的基本逻辑（实际上这段代码本身并不具备原子性）：

```c
// CAS
int CAS(int *addr, int expected, int new_value) {
    int tmp = *addr;
    if (*addr == expected) {
        *addr = new_value;
    }
    return tmp;
}

// FAA
int FAA(int *addr, int add_value) {
    int tmp = *addr;
    *addr = tmp + add_value;
    return tmp;
}
```



### Q：介绍一些几种经典的锁以及应用场景

> 下面的内容是基于小林哥的文章写的笔记：https://xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html
>
> 另外再推荐一个通俗易懂的理解：https://www.zhihu.com/question/66733477/answer/246535792

几种经典的锁有：互斥锁、自旋锁、读写锁、悲观锁、乐观锁。

#### 互斥锁与自旋锁

##### 区别

当已经有一个线程加锁后，其他线程加锁就会失败，互斥锁和自旋锁对于加锁失败后的处理方式不一样：

- 互斥锁加锁失败后，线程会释放 CPU，给其他线程；
- 自旋锁加锁失败后，线程会处于忙等待状态，直到拿到锁。

##### 互斥锁举例

举个例子，当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 就会加锁失败，于是就会释放 CPU 让给其他线程，自然线程 B 加锁的代码就会被阻塞。

##### 互斥锁加锁失败时内核过程

**对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的**。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。

因此，当互斥锁加锁失败时，线程会从用户态陷入内核态，帮内核帮我们切换线程，虽然简化了使用锁的难度，却存在一定的性能开销成本。而这个性能开销成本，指**两次线程上下文切换的成本：**

- 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
- 当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。

##### 互斥锁适用场景

这里注意：线程的上下文切换耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果锁住的代码执行时间比较短，那可能上下文切换的时间都比我们锁住的代码执行时间还要长。

所以，**如果能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**

##### 什么是自旋锁

自旋锁是通过 CPU 提供的 `CAS` 原子指令，在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

自旋锁利用一个变量 lock 来表示锁的状态。lock 为 1 表示已经有人拿锁，为 0 表示该锁空闲。

在加锁时，线程会通过 CAS 判断 lock 是否空闲，如果空闲则上锁，否则将一遍一遍重试。而放锁时，直接将 lock 设置为 0 表示其空闲。

```c
void lock_init(int *lock) {
    // 初始化自旋锁
    *lock = 0;
}

void lock(int *lock) {
    while (atomic_CAS(lock, 0, 1) != 0)
        ;	// 循环忙等
}

void unlock(int *lock) {
    *lock = 0;
}
```

##### 自旋锁使用场景

自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系。

注意：在单核 CPU 上，当使用自旋锁时需要用抢占式的调度器（即不断通过时钟中断一个线程而运行其他线程，否则自旋锁会一直霸占 CPU）。

互斥锁和自旋锁是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。

#### 读写锁

读写锁适用于能明确区分读操作和写操作的场景。如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。（注：陈硕说过，尽量避免使用读写锁）

##### 工作原理

- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，大大提高了共享资源的访问效率。因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
- 但是，一旦「写锁」被线程持有后，读线程的获取「读锁」的操作会被阻塞，而且其他写线程的获取「写锁」的操作也会被阻塞。

所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。

根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。

##### 读优先锁

读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性。

它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁时会被阻塞，并且在阻塞的过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放了读锁后，写线程 B 才成功获取写锁。

##### 写优先锁

写优先锁是优先服务写线程。

它的工作方式：当读线程 A 先持有了读锁，写线程 B 在获取写锁时会被阻塞，并且在阻塞的过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，等读线程 A 释放读锁后，线程 B 就可以成功获取读锁。

##### 评价

读优先锁对于读线程并发性更好，但也不是没有问题。如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。

写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。

即不管优先读锁还是写锁，对方都可能会出现饿死问题，因此就有了「公平读写锁」。

**公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。**

#### 乐观锁与悲观锁

前面提到的互斥锁、自旋锁、读写锁都属于悲观锁。悲观锁认为多线程同时修改共享数据的概率比较高，容易出现冲突，所以访问共享资源前要上锁。

相反，如果多线程同时修改共享资源的概率比较低，可以采用乐观锁。

乐观锁的工作方式：先修改共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程修改资源，那么操作完成；如果发现有其他线程已经修改过这个资源，就放弃本次操作。

由于乐观锁全程没有加锁，所以也叫做无锁编程。

##### 示例

一个场景例子：在线文档。

我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。

那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。

怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交早，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。

服务端要怎么验证是否冲突了呢？通常方案如下：

- 由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；
- 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。

实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。

乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**

#### 加餐

总结一下：

开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。

如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。

如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。

互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。

相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。

不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。



### Q：多线程的同步与互斥的方法

> **Q：线程间的通信方式有哪些？** 已经写过了

### Q：管道与消息队列的对比

> **Q：进程间的通信方式有哪些？** 的 加餐 部分已写

### Q：介绍一下信号，你对信号的理解？

> **Q：进程间的通信方式有哪些？** 的 信号 部分已经写过

### Q：信号与中断的相似点？区别？

> 转自：https://blog.csdn.net/wsx199397/article/details/28323415

信号与中断的相似点：

1. 采用了相同的异步通信方式；
2. 当检测出有信号或中断请求时，都暂停正在执行的程序而转去执行相应的处理程序；
3. 都在处理完毕后返回到原来的断点；
4. 对信号或中断都可进行屏蔽。

信号与中断的区别：

1. 中断有优先级，而信号没有优先级，所有的信号都是平等的；
2. 信号处理程序是在 用户态 下运行的，而中断处理程序是在 核心态 下运行；
3. 中断响应是及时的，而信号响应通常都有较大的时间延迟。



### Q：signal 和 sigaction 的区别（signal 的缺点）



### Q：kill 函数和 raise 函数



## 三、死锁(deadlock)

### Q：什么是死锁？

当有多个线程为了有限的资源竞争时，有的线程就会因为在某个时刻没有空闲的资源而陷入等待。而死锁就是指这一组中的每一个线程都在等待组内其他线程释放资源而造成的无限等待。



### Q：产生死锁的原因（四个必要条件）

- 互斥访问。互斥访问就是保证一个共享资源在同一时刻只能被至多一个线程访问。在有互斥访问的前提下，线程才会出现等待。
- 持有并等待。线程持有一些资源，并等待其他所需资源。
- 资源非抢占。一旦某个资源被持有，除非持有者主动放弃，否则其他竞争者都无法得到这个资源。
- 循环等待。一系列线程T0、T1、T2 ... ... Tn，其中 T0 等待 T1，T1 等待 T2，...，Tn-1 等待 Tn，Tn 等待 T0，因此形成了一个循环。



### Q：解除死锁的基本方法？

由于四个必要条件中的前三个都是描述场景本身的性质，只有最后一条 “循环等待” 和实际运行状态相关，因此为了恢复正常状态，我们需要打破循环等待的关系。

- 最直接的办法就是，找到这个环中任意的线程作为受害者，直接终止该线程并释放其占有资源。如果由于 分配/等待 关系过于复杂，终止一个线程后依旧形成环，我们就继续选择下一个线程释放其占有资源。
- 还可以让环中所有线程回退到之前的某一个状态再次运行。因为死锁的出现往往是由于特定的调度和触发时机而导致的，再次运行大概率就不会触发死锁了。



### Q：怎么预防死锁？

- 避免互斥访问。比如设置一个代理线程，专门用于管理对共享数据的访问与修改。共享数据只能通过代理线程来操作，其他线程需要向代理线程发送请求来完成对共享数据的访问。
  不足：大部分应用程序并不容易修改成此模式，而且对于每一个共享资源，都需要一个多余的代理线程来收集并执行对其的修改，这将会为系统带来很大的负担。
- 不允许持有并等待。可以要求线程在真正开始操作之前一次性申请所有的资源，一旦所需资源的任一资源不可用，则该线程就不能成功申请这一系列资源，并且线程还要释放已经占有的资源。
  不足：当资源的竞争程度较高时，一个线程很可能不能一次性拿到所有共享资源的使用权。因此可能进入 申请 - 释放 的循环中，这样造成了资源利用率低，甚至出现饥饿的情况。
- 允许资源被抢占。即运行一个线程抢占其他线程已经占有的资源。
  不足：有一个难点，我们需要保证被抢占的线程能够正确地恢复。
- 避免循环等待。**我们可以要求系统为线程编号，使其必须按照一定的顺序来获取资源**。这样获取资源的进度最靠前的线程一定能拿到所有所需资源，从而避免的循环等待，后面的资源同理。

综上分析，我们常采用为线程编号，使其必须按照一定的顺序来获取资源的方式来预防死锁。

#### 加餐

如何利用工具排查死锁？

> 看小林哥的文章：https://xiaolincoding.com/os/4_process/deadlock.html 



### Q：怎么避免死锁？（银行家算法）





### Q：哲学家就餐，读者写者，生产者消费者（怎么加锁解锁，伪代码） 

> 我下面都是基于小林哥这篇文章做的笔记：https://xiaolincoding.com/os/4_process/multithread_sync.html



### Q：什么是活锁(livelock)？

与死锁类似，都是锁的竞争者很长一段时间内无法获取锁进入临界区。

与死锁不同的是，死锁是多个线程等待对方先释放资源；而活锁是各自释放已经获取的资源并重试，如果两个线程执行速度相似，那么很有可能下一次又会出现同样的情况，如此反复始终进入不了临界区。

由于活锁产生的条件比较特殊，实际上没有发生线程阻塞，因此不同于死锁，活锁可能会自行解开。并没有一种统一的方法来避免，需要具体问题具体分析。如，让线程在获取资源失败后等待随机时间再开始下次尝试减少出现活锁的概率。

#### 加餐

形象的举例死锁活锁：

> 来自维基百科：https://zh.wikipedia.org/wiki/%E6%AD%BB%E9%94%81

假设两人正好面对面碰上对方：

- 死锁：两人互不相让，都在等对方先让开。
- 活锁：两人互相礼让，却恰巧站到同一侧，再次让开，又站到同一侧，同样的情况不断重复下去导致双方都无法通过。



## 四、内存管理

### Q：谈谈你对物理地址、逻辑(虚拟)地址、虚拟内存（非常重要）的理解

#### 物理地址与虚拟地址

从逻辑上来讲，我们可以把物理内存看成一个大数组，其中每个字节都可以通过与之唯一对应的地址进行访问，这个地址就是物理地址。而在引入虚拟内存后，应用程序就使用虚拟地址访问存储在内存中的数据和代码。

举个例子，

在 C 语言中，指针里面存储的地址就是虚拟地址。在程序执行过程中，CPU 会把虚拟地址转换为物理地址，然后通过物理地址访问物理内存。而因为透明性的存在，我们无法看到真实的物理地址。

#### 虚拟内存

##### why？为什么需要虚拟内存

先从没有虚拟内存时说起，当多个应用程序同时运行时，操作系统需要管理他们共同使用的物理内存资源。

一种简单的办法是：当一个应用程序 A 运行时，允许它访问所有的物理内存资源；在切换到另一个应用程序 B 的过程中，操作系统将应用程序 A 的所有内存数据都保存到存储设备中，然后将应用程序 B 的数据从存储设备加载到内存中。但是这种方法存在明显的弊端，由于读写存储设备的速度很慢，导致切换程序的时间开销太大。

另一种简单的办法是：让每个应用程序独立使用物理内存的一部分，数据一直驻留在内存中，在程序切换时不再需要操作存储设备。虽然性能优于前一种办法，但是也存在两个严重的弊端：

1. 无法保证不同的应用程序所使用的物理内存之间的隔离性，比如程序 A 运行过程中可能意外地写了程序 B 的物理内存，进而导致程序 B 运行错误。
2. 无法保证应用程序可用的地址空间是连续和统一的，这样增加了程序编写以及编译的复杂性。

基于上面的问题，现代操作系统在应用程序和物理内存之间加入了一个新的抽象：虚拟内存。应用程序在运行时只能使用虚拟地址，而 CPU 负责将虚拟地址翻译成物理地址，操作系统负责设置虚拟地址与物理地址之间的映射。

##### what？什么是虚拟内存

> 维基百科：https://zh.wikipedia.org/wiki/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98

虚拟内存是计算机系统内存管理的一种技术，并不是真实存在的，只是一种对物理内存的抽象。它给应用程序造成一种幻觉，使之认为自身拥有连续可用的内存，而实际上物理内存通常被分割成多个内存碎片，还有部分暂时存储在外部磁盘存储器中，在需要时进行数据交换。

相比没有使用虚拟内存技术的系统，虚拟内存有几个好处：

1. 操作系统仅将应用程序使用的虚拟地址映射到物理地址，从而提高了内存资源的利用率；
2. 每个应用程序只能看到自己的虚拟地址空间，从而保证了不同应用程序所用内存之间的隔离；
3. 每个应用程序的虚拟地址空间是统一的、连续的，从而降低了编程的复杂性。

#### 操作系统是如何管理虚拟地址与物理地址之间的关系？

操作系统是通过 MMU 来进行虚拟地址到物理地址的转换的，主要用到了**分页管理机制、分段管理机制以及段页式管理机制。**

##### 首先，什么是内存管理单元 MMU？

MMU 是 CPU 中的重要部件，负责虚拟地址到物理地址的转换。MMU 翻译出的物理地址将会通过总线传到相应的物理内存设备，从而完成相应的物理内存读取请求。

为了加速地址翻译的过程，现代 CPU 都引入了转址旁路缓存（TLB）。

![image-20220419113612306](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204191136422.png)

##### 分段管理机制

###### what？什么是分段机制

在分段机制下，操作系统以 “段” （一段连续的物理内存）的形式 管理/分配 物理内存。应用程序的虚拟地址空间由若干个不同大小的段组成，如代码段、数据段、栈段、堆段等。

> 分段机制下的**虚拟地址由两部分组成** ：
>
> 1. 段号。标识着该虚拟地址属于整个虚拟地址空间中的哪一个段；
> 2. 段内地址（或称段内偏移）。即相对于该段起始地址的偏移量。
>
> **段表**存储着一个虚拟地址空间中每一个分段的信息，其中包括段起始地址（对应与物理内存中段的起始地址）和段长。

###### 具体的翻译过程（虚拟内存和物理内存的映射过程）

1. MMU 通过段表基址寄存器找到段表的位置，结合待翻译的虚拟地址的段号，定位到段表中对应的位置；
2. 然后取出该段的起始地址（物理地址），加上待翻译的虚拟地址中的段内偏移，就能得到最终的物理地址。

段表中还有像段长等信息，可以用来检查虚拟地址是否超出合法范围等。

![image-20220419152645708](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204191526797.png)

###### 分段机制的缺点

不仅虚拟内存空间被划分为不同的段，物理内存也以段为单位进行分配。

1. 容易出现外部碎片。
   由于物理内存中的段不一定是相邻的，这就导致段式分配方式容易出现外部碎片，即在段与段之间留下碎片文件（不足以映射给虚拟地址空间中的段），从而造成物理内存资源利用率的降低。
   举个例子，如果一共有 6GB 的物理内存，目前被划分为 4 段进行分配，第一段为 0~2GB，第二段为 2~3GB，第三段为 3~5GB，第四段为 5~6GB；如果第二段和第四段被释放，然后又需要分配一个 2GB 的段，虽然此时空闲的物理内存总量为 2GB，但是由于这 2GB 内存不连续，因此分配还是会失败。
2. 内存交换效率低。
   对于多进程的系统来说，用分段的方式，内存碎片很容易产生，而产生了内存碎片就不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。



##### 分页管理机制

为了解决内存分段的内存碎片和内存交换效率低的问题，就出现了内存分页。

###### what？什么是分页机制

分页机制的基本思想就是将应用程序的虚拟内存空间和物理内存空间划分为连续的、等长的虚拟页。在 Linux 下，每一页的大小为 4KB。

###### 具体翻译的过程（虚拟内存和物理内存的映射过程）

1. MMU 通过页内基地址寄存器找到页表的位置，结合解析得到的虚拟地址的虚拟页号，定位到表中对应的条目；
2. 取出条目中存储的物理页号，加上待翻译虚拟地址中的页内偏移量得到最终的物理地址。

![image-20220419171542421](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204191715569.png)

###### 分页是如何解决分段的内存碎片、内存交换效率低的问题

分页机制按照固定页大小分配物理内存，释放时都是以页为单位，可有效避免分段机制中外部碎片的问题。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面**换出**到硬盘上，需要的时候再**换入**。这样的话，一次性写入磁盘的也只是少数的一个页或几个页，不会花太多时间，内存交换的效率就相对比较高

![image-20220419221129736](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204192211832.png)

分页的方式使得我们在加载程序的时候，不再需要一次性都把程序加载到物理内存中。我们完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。

###### 简单的分页的缺陷



###### 

###### 

##### 段页式管理机制





### Q：分页与分段的区别



### Q：缺页处理过程



### Q：页面置换算法，实现一个LRU页置换算法（或者FIFO置换算法）



### Q：堆和栈的区别；从堆和栈上建立对象哪个快？

> 这个问题并没有找到特别满意的答案，暂时参考的是这篇文章：https://blog.csdn.net/boyxiaolong/article/details/8543676

1. 从分配和释放上来看，堆在分配和释放时都要调用 malloc/free 函数，并且做了很多额外的工作，比如分配时会到堆空间中寻找足够大的空间，因为在多次分配释放后会造成空洞，这些都会花费一定的时间；而栈并不需要这些。
2. 从访问时间上来看，访问一个堆的具体单元需要两次访问内存，第一次取得指针，第二次才是真正的取数据；而栈只需要访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般不会被交换出去。

综上，从系统的角度来看，栈的效率更高。

### Q：程序从堆中动态分配内存时，虚拟内存上怎么操作的 



### Q：操作系统动态内存分配的几种策略 



### Q：谈谈内存泄漏和内存溢出 



### Q：常见内存分配方式和错误 

> 参考《高质量编程指南》第七章 内存管理

#### 内存分配方式

一般来说有以下三种：

1.  从静态存储区域分配。内存在程序编译的时候就已经分配好，这块内存在程序的整个运行期间都存在。如全局变量，static 变量。
2. 在栈上创建。在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。
3. 从堆上分配，亦称动态内存分配。程序在运行的时候用 malloc 或 new 申请任意多的内存，程序员自己负责在何时用 free 或 delete 释放内存。动态内存的生存期由我们决定，使用非常灵活，但问题也最多。

#### 常见的内存错误以及对策

发生内存错误是件非常麻烦的事情。编译器不能自动发现这些错误，通常是在程序运行时才能捕捉到。而这些错误大多没有明显的症状，时隐时现，增加了改错的难度。 有时用户怒气冲冲地把你找来，程序却没有发生任何问题，你一走，错误又发作了。

常见的内存错误及其对策如下：

- 内存分配未成功，却使用了它。
  编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是， 在使用内存之前检查指针是否为 NULL。如果指针 p 是函数的参数，那么在函数的入口处用 `assert(p != NULL)` 进行检查。如果是用 malloc 或 new 来申请内存，应该用 `if(p == NULL) `或 `if(p != NULL)` 进行防错处理。 
- 内存分配虽然成功，但是尚未初始化就引用它。
  犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。 内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。
- 内存分配成功并且已经初始化，但操作越过了内存的边界。 
  如，在使用数组时经常发生下标 “多 1” 或者 “少 1” 的操作。特别是在 for 循环语句中，循环次数很容易搞错，导致数组操作越界。
- 忘记了释放内存，造成内存泄露。 
  含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，我们看不到错误。终有一次程序突然死掉，系统出现提示：内存耗尽。 动态内存的申请与释放必须配对，程序中 malloc 与 free 的使用次数一定要相同， 否则肯定有错误（new/delete 同理）。
- 释放了内存却继续使用它。 有三种情况：
  1. 程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了 内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。
  2. 函数的 return 语句写错了，注意不要返回指向 “栈内存” 的 “指针” 或者 “引用”， 因为该内存在函数体结束时被自动销毁。 
  3. 使用 free 或 delete 释放了内存后，没有将指针设置为 NULL。导致产生 “野指针”。

几个规则：

- 用 malloc 或 new 申请内存之后，应该立即检查指针值是否为 NULL。 防止使用指针值为 NULL 的内存。 
- 不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。
- 避免数组或指针的下标越界，特别要当心发生 “多 1” 或者 “少 1” 操作。
- 动态内存的申请与释放必须配对，防止内存泄漏。 
- 用 free 或 delete 释放了内存之后，立即将指针设置为 NULL，防止 产生 “野指针”。



### Q：内部碎片和外部碎片 



### Q：内存对齐的规则和作用



### Q：



## 五、文件系统

### Q：文件读写使用的系统调用

### Q：文件系统的理解（EXT4，XFS，BTRFS） 

### Q：



## 六、设备管理

### Q：

### Q：

### Q：



## 七、基础理解

### Q：简单说下你对并发和并行的理解？

-  并行（parallel）：同一时刻，有多条指令在多个处理器上同时执行 
-  并发（concurrency）：同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得宏观上具有多个进程同时执行的效果  

举个例子：

```
并行是两个队列同时使用两台咖啡机
并发是两个队列交替使用一台咖啡机
```

![img](https://climber-picture-bed.oss-cn-hangzhou.aliyuncs.com/img/202204101835882.png)



### Q：什么是缓冲区溢出？有什么危害？



### Q：谈谈你对动态链接库和静态链接库的理解



### Q：一个程序从开始运行到结束的完整过程，你能说出来多少？



### Q：什么是用户态和内核态？



### Q：系统调用进入内核态的过程



### Q：一般情况下在 Linux/windows 平台下栈空间的大小 



### Q：外中断和异常有什么区别？



### Q：中断、陷阱、故障和终止



### Q：谈一谈可重入函数和可重入内核



### Q：？？？可重入与线程安全、不可重入标志3点？？？



### Q：海量数据的bitmap使用原理



### Q：




